Créative Code paris Exhibition
Jeudi 20 juin 2019 à la Folie Numérique

--------------------------

Pour cette dernière soirée de la saison, nous avons invité les participant(e)s des codes kitchen à venir présenter les travaux qu'ils avaient réalisé durant les soirées "code kitchen".
Plusieurs personnes ont répondu à l'appel, dont voici la liste :

- Michel Bret et Marie-Hélène Tramus
- Florian Rouzaud Cornabas
- Stanislas Marçais
- Grégory Jarrige
- Fred Cecilia
- Antoine Zanuttini 
- Erwan Boehm

Des photos prises durant la soirée, vont être postées sur la page de l'événement :
https://www.meetup.com/fr-FR/CreativeCodeParis/events/258155818/

Vous trouverez ci-dessous un descriptif détaillé des travaux présentés durant la soirée. Bonne lecture.

-----------------------------

Attracteur de rêve - Michel Bret et Marie-Hélène Tramus
Installation artistique interactive

Nous n'avons pas si souvent l'occasion, à CreativeCodeParis, de rencontrer des pionniers de l'image de synthèse.
C'est pourtant bien ce qui nous est arrivé en novembre 2018, quand Michel Bret et Marie-Hélène Tramus sont venus participer à notre première soirée "code kitchen".

Lors de cette session, Michel et Marie-Hélène se sont prêtés au jeu et ont eu envie de développer à partir l'un des thèmes tirés au sort : le rêve. 
Michel et Marie-Hélène ont eu par la suite le plaisir de présenter une version finalisée de ce travail lors du Festival LAVAL VIRTUAL RECTO VRSO 2019. 

Le fonctionnement de leur installation est le suivant :

"Choisissez  quelques  mots  affichés  sur  l'écran pour  écrire  votre  "rêve",  et  l'attracteur  de  rêve  l'interprétera visuellement. Aux  mots  correspondent  de  petites  séquences  animées, l’attracteur de rêves produira par mélanges et transparences des   images   mappées   sur   plusieurs   surfaces   évoluant dynamiquement  et  simultanément  selon  la  musique;  elles seront  aussi  démultipliées  par  l’algorithme  d'auto  mapping consistant  à  mapper  récursivement  des  séquences  animées sur  elles-mêmes,  donnant  ainsi  une  perception  fractale  de l'espace  et  du  temps.  Des  réseaux  neuronaux  interposés entre le son et l’image assurent une interprétation visuelle et non triviale de celui-ci. À chaque instant le processus peut être réinitialisé et un nouveau rêve visualisé."

Voici quelques liens concernant Michel Bret et Marie-Hélène Tramus :

- une présentation de la formation ATI par ses fondateurs :

http://www.ati-paris8.fr/index.php?page=historique&lang=fr

- une rétrospective des travaux de Michel Bret :

http://www.archives-video.univ-paris8.fr/bret_sommaire.php

- quelques liens complémentaires pour en savoir plus :

https://fr.wikipedia.org/wiki/Michel_Bret
http://histoire3d.siggraph.org/index.php/Marie-H%C3%A9l%C3%A8ne_Tramus

------------------------

Florian Rouzaud Cornabas 

Florian est un "visual artist" qui travaille avec différents médias (photos, vidéo, électronique...). Il développe des projets artistiques qui nous invitent à la rêverie, et nous questionnent aussi. Il est venu nous présenter certains de ses travaux en avril 2019.

Présentation de son installation qu'il a intitulée : "Interface" 

"Nos villes sont le reflet des transformations de nos sociétés. Interface est un paysage urbain qui suit une grammaire architecturale établie tout en étant généré aléatoirement par ordinateur. Sa réalisation en impression 3d symbolise en elle-même le pont entre technologie et matérialité, elle rend tangible l’univers numérique. Les structures géométriques qui composent cette installation sont le théâtre d’un jeu de lumière battant au rythme des pulsations cardiaques de chacun de ses spectateurs. Ces vibrations organiques en créant une interface entre l’humain et la technologie numérique donnent vie à cette fenêtre digitale."

Quelques liens complémentaires pour découvrir le travail de Florian :

http://instagram.com/florianrouzaudcornabas

http://vimeo.com/florianrouzaudcornabas

http://facebook.com/FlorianRouzaudCornabasArt


-------------------------

Stanislas Marçais, alias Stan Le Punk 

Stan porte la double casquette de graphiste et d'artiste codeur. Inspiré par le thème "Générateur de monde", Stan a développé un générateur de ville. L'application se compose d'un générateur de bâtiments, bâtiment qui sont répartis sur une carte dessinée par un algorithme "cartographe", ce dernier assurant le rôle de l'urbaniste. Application visuelle développée en Processing.

Quelques liens pour découvrir le travail de Stan :

http://stanlepunk.xyz 

Le code source du générateur de monde de Stan se trouve ici :

https://github.com/StanLepunK/Monde


---------------------------------

Grégory Jarrige

Grégory a eu envie d'explorer le thème de la "perte d'identité", qu'il avait lui même proposé, inspiré par la lecture d'un roman de Philip K. Dick, "Substance mort" (titre original : "A scanner darkly"). 

A partir d'une photo de Ninja (son chat), Grégory s'est amusé à développer une histoire dans laquelle Ninja, quelque peu déprimé, souffirait de troubles de la personnalité. 
Cette histoire capilotractée était un prétexte utilisé par Grégory pour réexplorer de vieux algorithmes de traitement d'image, en les associant à l'API Canvas 2D et à des techniques Javascript récentes (comme par exemple les Promises pour le chargement asynchrone des images). 
Grégory en a profité pour glisser un clin d'oeil à un autre thème des "code kitchen" : générateur de monde. Pour cela, il a utilisé la photo de Ninja pour générer une sorte de paysage 3D (composé de cylindres verticaux de longueur variables) via le framework AFrame (framework dédié à la VR).

Lien vers le dépôt github du projet :

https://github.com/gregja/ninjaOnMeetup


------------------------

Fred Cecilia

BrainArt est une installation à la frontière entre art et science basée sur les neurosciences, dans laquelle l’activité cérébrale contrôle en temps réel musique et image, pour créer une performance audiovisuelle unique .

Le principe de l'installation est d'exploiter les ondes alpha du cerveau, via un casque spécial capable de capter ces ondes. 


--------------------------------

Antoine Zanuttini 

Antoine a réalisé deux animations - de type shaders - qu'il a programmées en GLSL en utilisant une technique de rendu qui porte le nom de "ray marching". 

Pour la première animation, Antoine a tiré son inspiration d'un roman de science-fiction d'Arthur C. Clarke, qui s'intitule "Rama" (paru en 1973). Ce roman raconte l'histoire d'un immense vaisseau cylindrique d'origine inconnue, qui pénètre dans le Système solaire au XXIIe siècle. Antoine a conservé l'idée du vaisseau pour créer une sorte de tunnel constitué de triangles. Les couleurs retenues par Antoine, ainsi que l'échelle et l'étrangeté de la structure, nous transmettent une délicieuse sensation de vertige. 

Pour la seconde animation, Antoine a créé un paysage étrange parcouru de faisceaux lasers qui se comportent comme des portails vers un autre monde. Comme si deux mondes parallèles coexistaient dans un même espace mais dans des dimensions différentes, et que les faisceaux lasers nous révélaient deux réalités différentes. L'effet est difficile à décrire, mais il est enthousiasmant.

Quelques liens complémentaires sur les activités d'Antoine :

- son portail sur itch, sur lequel on peut ses travaux les plus récents
https://nusan.itch.io/

- sa chaîne youtube sur laquelle il présente des expériences de live coding:
https://www.youtube.com/channel/UCdiiD1ukw39XTRj9h6LKCeQ


---------------------------

Erwan Boehm

Erwan a développé une application de réalité augmentée, ARCC, qui permet a l'utilisateur, par exemple, de dessiner des bandeaux de texte dans l'espace, de screenshooter la réalité, de remonter le temps (mode rafale)...

Erwan nous présente ci-dessous les grandes lignes du fonctionnement de ARCC:

L’application est développée en C++ grâce à openFrameworks (une librairie de creative coding). 
Grâce à l’utilisation d’addons (ofxAddons) développés par une large communauté, openFrameworks permet le développement (par la communauté) de programmes utilisant du Machine Learning, des webcams, la kinect et pleins d’autres librairies/outils.
Pour ma part j’ai développé mon propre Addon (ofxArcore2) permet d’utiliser ArCore (un sdk de réalité augmentée développé par Google) avec openFrameworks.
ArCore nous donne la position du téléphone dans l’espace via une matrice de position.
Il nous fournit aussi plusieurs APIs telles que :
Augmented Images: le tracking d’images 2D (marqueurs)
Hit testing : permet de matcher un point (2D) de l'écran avec un point dans l’espace 3D
Plane détection : Qui permet de localiser les surfaces planes (murs, sol)
Point Cloud : Qui renvoie un nuage de point (utile pour la reconstruction 3D)
J’ai donc implémenté ces APIs dans un module openFrameworks, puis je m’en suis servi pour réaliser mon application.

L’application est disponible en téléchargement sur les smartphones Android compatible ArCore a cette adresse : 
https://play.google.com/store/apps/details?id=cc.openframeworks.ardrawing

Lien vers les addons ofxAddons :
http://ofxaddons.com/categories

Lien vers l'addon développé par Erwan :
https://github.com/boehm-e/ofxARCore2

Lien vers différents ScreenShots : 
https://drive.google.com/drive/folders/1NJZ-AInD5FDkuwy_TUKndnSbn_Y30lpG?usp=sharing

Compte github d'Erwan :
http://github.com/boehm-e






