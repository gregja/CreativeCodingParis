# Créative Code paris Exhibition - 1ère édition

Jeudi 20 juin 2019 à la Folie Numérique

--------------------------

De septembre 2018 à mai 2019, au meetup CreativeCodeParis, nous avons organisé des soirées coding, à un rythme bimestriel (en alternance avec des soirées de talks). Nous avons intitulé ces soirées coding des "code kitchen". A chaque nouvelle soirée, les participants proposaient des thèmes et nous tirions au sort 3 thèmes au hasard, à charge pour chacun(e) de choisir son thème de prédilection, et de le développer à sa manière, avec les outils (de programmation) de son choix.

Nous avions pour objectif d'organiser en juin 2019 une exposition des travaux réalisés durant les "code kitchen", et nous avons réalisé cette exposition le jeudi 20 juin, à la Folie Numérique.

Pour cette dernière soirée de la saison, nous avons donc invité les participant(e)s des "codes kitchen" à venir présenter les travaux qu'ils/elles avaient réalisés durant ces soirées.

Plusieurs personnes ont répondu à l'appel, dont voici la liste :

- Michel Bret et Marie-Hélène Tramus
- Florian Rouzaud Cornabas
- Stanislas Marçais
- Grégory Jarrige
- Fred Cecilia
- Antoine Zanuttini 
- Erwan Boehm

Une première série de photos, prises durant la soirée, a été postée sur la page de l'événement (d'autres devraient suivre prochainement) :

https://www.meetup.com/fr-FR/CreativeCodeParis/photos/30138860/482999120/?photoId=482999120&photoAlbumId=30138860

Vous trouverez ci-dessous un descriptif des travaux présentés durant la soirée. Bonne lecture.

-----------------------------

## Michel Bret et Marie-Hélène Tramus 
Attracteur de rêve, installation artistique interactive

Nous n'avons pas si souvent l'occasion, à CreativeCodeParis, de rencontrer des pionniers de l'image de synthèse.
C'est pourtant bien ce qui nous est arrivé en novembre 2018, quand Michel Bret et Marie-Hélène Tramus sont venus participer à notre première soirée "code kitchen".

Lors de cette soirée, Michel et Marie-Hélène ont souhaité développer un projet à partir l'un des thèmes tirés au sort : le rêve. 
Une version finalisée de ce travail a été présentée lors du Festival LAVAL VIRTUAL RECTO VRSO 2019. 

Le fonctionnement de leur installation est le suivant :

"Choisissez  quelques  mots  affichés  sur  l'écran pour  écrire  votre  "rêve",  et  l'attracteur  de  rêve  l'interprétera visuellement. Aux  mots  correspondent  de  petites  séquences  animées, l’attracteur de rêves produira par mélanges et transparences des   images   mappées   sur   plusieurs   surfaces   évoluant dynamiquement  et  simultanément  selon  la  musique;  elles seront  aussi  démultipliées  par  l’algorithme  d'auto  mapping consistant  à  mapper  récursivement  des  séquences  animées sur  elles-mêmes,  donnant  ainsi  une  perception  fractale  de l'espace  et  du  temps.  Des  réseaux  neuronaux  interposés entre le son et l’image assurent une interprétation visuelle et non triviale de celui-ci. À chaque instant le processus peut être réinitialisé et un nouveau rêve visualisé."

Voici quelques liens concernant Michel Bret et Marie-Hélène Tramus :

- présentation du parcours de Michel Bret : http://histoire3d.siggraph.org/index.php/Michel_Bret

- présentation du parcours de Marie-Hélène Tramus : http://histoire3d.siggraph.org/index.php/Marie-H%C3%A9l%C3%A8ne_Tramus

- présentation de la formation ATI Paris 8 : http://www.ati-paris8.fr/index.php?page=historique&lang=fr

- rétrospective des travaux de Michel Bret : http://www.archives-video.univ-paris8.fr/bret_sommaire.php


------------------------

## Florian Rouzaud Cornabas 

Florian est un "visual artist" qui travaille avec différents médias (photos, vidéo, électronique...). Il développe des projets artistiques qui nous invitent à la rêverie, et nous questionnent aussi. Il est venu nous présenter certains de ses travaux en avril 2019.

Présentation de son installation qu'il a intitulée : "Interface" 

"Nos villes sont le reflet des transformations de nos sociétés. Interface est un paysage urbain qui suit une grammaire architecturale établie tout en étant généré aléatoirement par ordinateur. Sa réalisation en impression 3d symbolise en elle-même le pont entre technologie et matérialité, elle rend tangible l’univers numérique. Les structures géométriques qui composent cette installation sont le théâtre d’un jeu de lumière battant au rythme des pulsations cardiaques de chacun de ses spectateurs. Ces vibrations organiques en créant une interface entre l’humain et la technologie numérique donnent vie à cette fenêtre digitale."

Quelques liens complémentaires pour découvrir le travail de Florian :

http://instagram.com/florianrouzaudcornabas

http://vimeo.com/florianrouzaudcornabas

http://facebook.com/FlorianRouzaudCornabasArt


-------------------------

## Stanislas Marçais, alias Stan Le Punk 

Stan porte la double casquette de graphiste et d'artiste codeur. Inspiré par le thème "Générateur de monde", Stan a développé un générateur de ville. L'application se compose d'un générateur de bâtiments, bâtiments qui sont répartis sur une carte dessinée par un algorithme "cartographe", ce dernier assurant le rôle de l'urbaniste. 

Application visuelle développée en Processing.

Quelques liens pour découvrir le travail de Stan : http://stanlepunk.xyz 

Le code source du générateur de monde de Stan se trouve ici : https://github.com/StanLepunK/Monde

A noter que Stan est le créateur du framework Romanesco pour Processing, que vous pouvez télécharger ici : https://github.com/StanLepunK/ROMANESCO-Processing


---------------------------------

## Grégory Jarrige

Grégory a eu envie d'explorer le thème de la "perte d'identité", qu'il avait lui même proposé, inspiré par la lecture d'un roman de Philip K. Dick, "Substance mort" (titre original : "A scanner darkly"). 

A partir d'une photo de Ninja (son chat), Grégory s'est amusé à développer une histoire dans laquelle Ninja, quelque peu déprimé, souffirait de troubles de la personnalité (rassurez-vous, Ninja va très bien). 

Cette histoire capilotractée était un prétexte pour revisiter de vieux algorithmes de traitement d'image, en les associant à l'API Canvas 2D et à des techniques Javascript modernes.

Il en a profité pour glisser un clin d'oeil à un autre thème des "code kitchen" : "générateur de monde". Pour cela, il a utilisé la photo de Ninja pour générer un paysage 3D via le framework AFrame (framework dédié à la VR).

Lien vers le dépôt github du projet (dans lequel vous trouverez une description assez détaillée des techniques utilisées) : https://github.com/gregja/ninjaOnMeetup


------------------------

## Fred Cecilia

BrainArt est une installation à la frontière entre art et science basée sur les neurosciences, dans laquelle l’activité cérébrale contrôle en temps réel musique et image, pour créer une performance audiovisuelle unique .

Le principe de l'installation est d'exploiter les ondes alpha du cerveau, via un casque spécial capable de capter ces ondes. 
Le casque c'est le Melomind de myBrain Technologies.
Le graphique c'est du processing  avec un surcouche en Scala.
Le son c'est un synthétiseur logiciel qui s'appelle Equator de Roli, synthé qui a la particularité de gérer le protocole MPE (Multidimensional Polyphonic Expression).
Le casque envoie les informations en bluetooth au téléphone de Fred, qui traite ces informations, puis extrait quelques features qui sont ensuite transmis en OSC à son ordinateur.
Sur l'ordinateur, une application génère des message MIDI (Note, CC, Channel Pressure) à partir des features.
Ces messages sont interprétés pour générer du son par le synthétiseur et du visuel via l'API de processing. 

Le portail de Fred, point d'entrée vers ses différents projets : http://www.naikyworld.com/


--------------------------------

## Antoine Zanuttini 

Très intéressé par le thème "Générateur de monde", Antoine nous a présenté deux animations 3D. 

Pour la première animation, Antoine a tiré son inspiration d'un roman de science-fiction d'Arthur C. Clarke, qui s'intitule "Rama" (publié en 1973). Ce roman raconte l'histoire d'un immense vaisseau cylindrique d'origine inconnue, qui pénètre dans le Système solaire au XXIIe siècle. Antoine a conservé l'idée du vaisseau pour créer un tunnel constitué de structures triangulaires, tunnel dans lequel la caméra se déplace. 

Pour la seconde animation, Antoine a créé un paysage étrange quadrillé de faisceaux rougeoyants qui se déplacent et laissent apparaître à chaque passage... un autre paysage. Comme si deux mondes parallèles coexistaient dans un même espace mais dans des dimensions différentes, et que les faisceaux nous laissaient entrevoir ces deux réalités différentes. L'effet est difficile à décrire, mais il est enthousiasmant.

Antoine a créé ces images animées en "live coding" grâce au "raymarching", une technique proche du raytracing. En utilisant le GLSL, un language prévu pour la carte graphique, il est possible de créer des formes 3D à partir de formules mathématiques simples qui se combinent pour donner une infinité de possibilités. Pas de maillages ou de vertex ici, uniquement le calcul, pour chaque pixel, de sa collision avec la surface décrite. La technique du "raymarching" permet ainsi de créer rapidement, avec très peu de code, des scenes procédurales intéressantes visuellement.

Le portail d'Antoine sur lequel on peut voir ses travaux les plus récents : https://nusan.itch.io/

La chaîne twitch ou Antoine crée en live chaque lundi soir (21h): https://www.twitch.tv/nusan_fx

Les vods de ces lives: https://www.youtube.com/channel/UCdiiD1ukw39XTRj9h6LKCeQ

Pour débuter en language GLSL: https://thebookofshaders.com/

Pour en apprendre plus sur la technique du raymarching: https://www.youtube.com/channel/UCcAlTqd9zID6aNX3TzwxJXg

Et le site principal pour découvrir de belles choses faites avec ce type de techniques: https://www.shadertoy.com

A noter que Antoine utilise l'éditeur de code Bonzomatic, pour ses expériences de live coding GLSL.


---------------------------

## Erwan Boehm

Erwan a développé une application de réalité augmentée, ARCC, qui permet a l'utilisateur, par exemple, de dessiner des bandeaux de texte dans l'espace, de screenshooter la réalité, de remonter le temps (mode rafale)...

Erwan nous présente ci-dessous les grandes lignes du fonctionnement de ARCC:

L’application est développée en C++ grâce à openFrameworks (une librairie de creative coding). 
Grâce à l’utilisation d’addons (ofxAddons) développés par une large communauté, openFrameworks permet le développement (par la communauté) de programmes utilisant du Machine Learning, des webcams, la kinect et pleins d’autres librairies/outils.
Pour ma part j’ai développé mon propre Addon (ofxArcore2) permet d’utiliser ArCore (un sdk de réalité augmentée développé par Google) avec openFrameworks.
ArCore nous donne la position du téléphone dans l’espace via une matrice de position.
Il nous fournit aussi plusieurs APIs telles que :
Augmented Images: le tracking d’images 2D (marqueurs)
Hit testing : permet de matcher un point (2D) de l'écran avec un point dans l’espace 3D
Plane détection : Qui permet de localiser les surfaces planes (murs, sol)
Point Cloud : Qui renvoie un nuage de point (utile pour la reconstruction 3D)
J’ai donc implémenté ces APIs dans un module openFrameworks, puis je m’en suis servi pour réaliser mon application.

L’application est disponible en téléchargement sur les smartphones Android compatible ArCore a cette adresse : 
https://play.google.com/store/apps/details?id=cc.openframeworks.ardrawing

Lien vers les addons ofxAddons :
http://ofxaddons.com/categories

Lien vers l'addon développé par Erwan :
https://github.com/boehm-e/ofxARCore2

Lien vers différents ScreenShots : 
https://drive.google.com/drive/folders/1NJZ-AInD5FDkuwy_TUKndnSbn_Y30lpG?usp=sharing

Compte github d'Erwan :
http://github.com/boehm-e






